{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
    "    # https://github.com/yandexdataschool/Practical_RL/issues/256\n",
    "    # https://stackoverflow.com/a/62482183\n",
    "    !pip uninstall -y tensorflow\n",
    "    !pip install tensorflow-gpu==1.13.1 keras==2.3.1\n",
    "    \n",
    "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
    "\n",
    "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week07_seq2seq/basic_model_tf.py\n",
    "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week07_seq2seq/he-pron-wiktionary.txt\n",
    "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week07_seq2seq/main_dataset.txt\n",
    "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week07_seq2seq/voc.py\n",
    "\n",
    "    !touch .setup_complete\n",
    "\n",
    "# This code creates a virtual display to draw game images on.\n",
    "# It will have no effect if your machine has a monitor.\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
    "    !bash ../xvfb start\n",
    "    os.environ['DISPLAY'] = ':1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "[3, 2, 1, 0, 1, 4]\n",
      "[0, 1, 0, 1, 4]\n"
     ]
    }
   ],
   "source": [
    "def f(x, l=[]):\n",
    "    for i in range(x):\n",
    "        l.append(i * i)\n",
    "    print(l)\n",
    "\n",
    "f(2)\n",
    "f(3, [3, 2, 1])\n",
    "f(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2]\n",
    "b = list(a)\n",
    "a is b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning for seq2seq\n",
    "\n",
    "This time we'll solve a problem of transribing hebrew words in english, also known as g2p (grapheme2phoneme)\n",
    "\n",
    " * word (sequence of letters in source language) -> translation (sequence of letters in target language)\n",
    "\n",
    "Unlike what most deep learning practitioners do, we won't only train it to maximize likelihood of correct translation, but also employ reinforcement learning to actually teach it to translate with as few errors as possible.\n",
    "\n",
    "\n",
    "### About the task\n",
    "\n",
    "One notable property of Hebrew is that it's consonant language. That is, there are no wovels in the written language. One could represent wovels with diacritics above consonants, but you don't expect people to do that in everyay life.\n",
    "\n",
    "Therefore, some hebrew characters will correspond to several english letters and others - to none, so we should use encoder-decoder architecture to figure that out.\n",
    "\n",
    "![img](https://esciencegroup.files.wordpress.com/2016/03/seq2seq.jpg)\n",
    "_(img: esciencegroup.files.wordpress.com)_\n",
    "\n",
    "Encoder-decoder architectures are about converting anything to anything, including\n",
    " * Machine translation and spoken dialogue systems\n",
    " * [Image captioning](http://mscoco.org/dataset/#captions-challenge2015) and [image2latex](https://openai.com/requests-for-research/#im2latex) (convolutional encoder, recurrent decoder)\n",
    " * Generating [images by captions](https://arxiv.org/abs/1511.02793) (recurrent encoder, convolutional decoder)\n",
    " * Grapheme2phoneme - convert words to transcripts\n",
    "  \n",
    "We chose simplified __Hebrew->English__ machine translation for words and short phrases (character-level), as it is relatively quick to train even without a gpu cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If True, only translates phrases shorter than 20 characters (way easier).\n",
    "EASY_MODE = True\n",
    "# Useful for initial coding.\n",
    "# If false, works with all phrases (please switch to this mode for homework assignment)\n",
    "\n",
    "MODE = \"he-to-en\"  # way we translate. Either \"he-to-en\" or \"en-to-he\"\n",
    "# maximal length of _generated_ output, does not affect training\n",
    "MAX_OUTPUT_LENGTH = 50 if not EASY_MODE else 20\n",
    "REPORT_FREQ = 100  # how often to evaluate validation score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: preprocessing\n",
    "\n",
    "We shall store dataset as a dictionary\n",
    "`{ word1:[translation1,translation2,...], word2:[...],...}`.\n",
    "\n",
    "This is mostly due to the fact that many words have several correct translations.\n",
    "\n",
    "We have implemented this thing for you so that you can focus on more interesting parts.\n",
    "\n",
    "\n",
    "__Attention python2 users!__ You may want to cast everything to unicode later during homework phase, just make sure you do it _everywhere_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size =  130114\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "word_to_translation = defaultdict(list)  # our dictionary\n",
    "\n",
    "bos = '_'\n",
    "eos = ';'\n",
    "\n",
    "with open(\"main_dataset.txt\") as fin:\n",
    "    for line in fin:\n",
    "\n",
    "        en, he = line[:-1].lower().replace(bos, ' ').replace(eos,\n",
    "                                                             ' ').split('\\t')\n",
    "        word, trans = (he, en) if MODE == 'he-to-en' else (en, he)\n",
    "\n",
    "        if len(word) < 3:\n",
    "            continue\n",
    "        if EASY_MODE:\n",
    "            if max(len(word), len(trans)) > 20:\n",
    "                continue\n",
    "\n",
    "        word_to_translation[word].append(trans)\n",
    "\n",
    "print(\"size = \", len(word_to_translation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unique lines in source language\n",
    "all_words = np.array(list(word_to_translation.keys()))\n",
    "# get all unique lines in translation language\n",
    "all_translations = np.array(\n",
    "    [ts for all_ts in word_to_translation.values() for ts in all_ts])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split the dataset\n",
    "\n",
    "We hold out 10% of all words to be used for validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_words, test_words = train_test_split(\n",
    "    all_words, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building vocabularies\n",
    "\n",
    "We now need to build vocabularies that map strings to token ids and vice versa. We're gonna need these fellas when we feed training data into model or convert output matrices into english words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from voc import Vocab\n",
    "inp_voc = Vocab.from_lines(''.join(all_words), bos=bos, eos=eos, sep='')\n",
    "out_voc = Vocab.from_lines(''.join(all_translations), bos=bos, eos=eos, sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines\n",
      "['משתמש:צלף/!' 'סימן קריאה' 'תבנית:!!' '$9.99' \"תבנית:'\"]\n",
      "\n",
      "words to ids (0 = bos, 1 = eos):\n",
      "[[  0 127 138 139 127 138  27 135 125 132  16   3   1]\n",
      " [  0 130 122 127 128   2 136 137 122 113 117   1   1]\n",
      " [  0 139 114 129 122 139  27   3   3   1   1   1   1]\n",
      " [  0   6  26  15  26  26   1   1   1   1   1   1   1]\n",
      " [  0 139 114 129 122 139  27   8   1   1   1   1   1]]\n",
      "\n",
      "back to words\n",
      "['משתמש:צלף/!', 'סימן קריאה', 'תבנית:!!', '$9.99', \"תבנית:'\"]\n"
     ]
    }
   ],
   "source": [
    "# Here's how you cast lines into ids and backwards.\n",
    "batch_lines = all_words[:5]\n",
    "batch_ids = inp_voc.to_matrix(batch_lines)\n",
    "batch_lines_restored = inp_voc.to_lines(batch_ids)\n",
    "\n",
    "print(\"lines\")\n",
    "print(batch_lines)\n",
    "print(\"\\nwords to ids (0 = bos, 1 = eos):\")\n",
    "print(batch_ids)\n",
    "print(\"\\nback to words\")\n",
    "print(batch_lines_restored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw word/translation length distributions to estimate the scope of the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   20.,    93.,  2164.,  5532.,  7753.,  9500.,  9435.,  8577.,\n",
       "         8614.,  9449., 10091., 10964., 11044., 10702.,  9206.,  7788.,\n",
       "         6454.,  5470.,  4461.,  3642.]),\n",
       " array([ 1.  ,  1.95,  2.9 ,  3.85,  4.8 ,  5.75,  6.7 ,  7.65,  8.6 ,\n",
       "         9.55, 10.5 , 11.45, 12.4 , 13.35, 14.3 , 15.25, 16.2 , 17.15,\n",
       "        18.1 , 19.05, 20.  ]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"words\")\n",
    "plt.hist(list(map(len, all_words)), bins=20)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('translations')\n",
    "plt.hist(list(map(len, all_translations)), bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: deploy encoder-decoder (1 point)\n",
    "\n",
    "__assignment starts here__\n",
    "\n",
    "Our architecture consists of two main blocks:\n",
    "* Encoder reads words character by character and outputs code vector (usually a function of last RNN state)\n",
    "* Decoder takes that code vector and produces translations character by character\n",
    "\n",
    "Than it gets fed into a model that follows this simple interface:\n",
    "* __`model.symbolic_translate(inp, **flags) -> out, logp`__ - takes symbolic int32 matrix of hebrew words, produces output tokens sampled from the model and output log-probabilities for all possible tokens at each tick.\n",
    "   * if given flag __`greedy=True`__, takes most likely next token at each iteration. Otherwise samples with next token probabilities predicted by model.\n",
    "* __`model.symbolic_score(inp, out, **flags) -> logp`__ - takes symbolic int32 matrices of hebrew words and their english translations. Computes the log-probabilities of all possible english characters given english prefices and hebrew word.\n",
    "* __`model.weights`__ - weights from all model layers [a list of variables]\n",
    "\n",
    "That's all! It's as hard as it gets. With those two methods alone you can implement all kinds of prediction and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "s = tf.InteractiveSession()\n",
    "\n",
    "# ^^^ if you get \"variable *** already exists\": re-run this cell again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /notebooks/Practical_RL/week07_seq2seq/basic_model_tf.py:25: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /opt/conda/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /notebooks/Practical_RL/week07_seq2seq/basic_model_tf.py:53: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /opt/conda/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from basic_model_tf import BasicTranslationModel\n",
    "model = BasicTranslationModel('model', inp_voc, out_voc,\n",
    "                              emb_size=64, hid_size=128)\n",
    "\n",
    "s.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /notebooks/Practical_RL/week07_seq2seq/basic_model_tf.py:142: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.random.categorical instead.\n",
      "\n",
      "Symbolic_translate output:\n",
      " Tensor(\"transpose_1:0\", shape=(?, ?), dtype=int32) Tensor(\"LogSoftmax:0\", shape=(?, ?, 283), dtype=float32)\n",
      "\n",
      "Sample translations:\n",
      " [[  0 195 237  57  12 280 223  31  46 114 101]\n",
      " [  0  40 254  24 260 140  67  45 198  94 202]\n",
      " [  0  80 251 181 260 110  52  86  41 109  74]]\n"
     ]
    }
   ],
   "source": [
    "# Play around with symbolic_translate and symbolic_score\n",
    "inp = tf.placeholder_with_default(np.random.randint(\n",
    "    0, 10, [3, 5], dtype='int32'), [None, None])\n",
    "out = tf.placeholder_with_default(np.random.randint(\n",
    "    0, 10, [3, 5], dtype='int32'), [None, None])\n",
    "\n",
    "# translate inp (with untrained model)\n",
    "sampled_out, logp = model.symbolic_translate(inp, greedy=False)\n",
    "print(\"\\nSymbolic_translate output:\\n\", sampled_out, logp)\n",
    "print(\"\\nSample translations:\\n\", s.run(sampled_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Symbolic_score output:\n",
      " Tensor(\"LogSoftmax_1:0\", shape=(?, ?, 283), dtype=float32)\n",
      "\n",
      "Log-probabilities (clipped):\n",
      " [[[  0.        -69.07755   -69.07755   -69.07755   -69.07755  ]\n",
      "  [ -5.648086   -5.648397   -5.652492   -5.6411448  -5.6520305]]\n",
      "\n",
      " [[  0.        -69.07755   -69.07755   -69.07755   -69.07755  ]\n",
      "  [ -5.6440487  -5.645118   -5.6477404  -5.6432157  -5.646838 ]]\n",
      "\n",
      " [[  0.        -69.07755   -69.07755   -69.07755   -69.07755  ]\n",
      "  [ -5.654624   -5.644845   -5.6423388  -5.644101   -5.643965 ]]]\n"
     ]
    }
   ],
   "source": [
    "# score logp(out | inp) with untrained input\n",
    "logp = model.symbolic_score(inp, out)\n",
    "print(\"\\nSymbolic_score output:\\n\", logp)\n",
    "print(\"\\nLog-probabilities (clipped):\\n\", s.run(logp)[:, :2, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare any operations you want here\n",
    "input_sequence = tf.placeholder('int32', [None, None])\n",
    "greedy_translations, logp = model.symbolic_translate(input_sequence, greedy=True) #<YOUR CODE: build symbolic translations with greedy = True>\n",
    "\n",
    "\n",
    "def translate(lines):\n",
    "    \"\"\"\n",
    "    You are given a list of input lines. \n",
    "    Make your neural network translate them.\n",
    "    :return: a list of output lines\n",
    "    \"\"\"\n",
    "    # Convert lines to a matrix of indices\n",
    "    lines_ix = inp_voc.to_matrix(lines)\n",
    "\n",
    "    # Compute translations in form of indices\n",
    "#     trans_ix = s.run(greedy_translations, { <YOUR CODE: feed_dict> })\n",
    "    trans_ix = s.run(greedy_translations, feed_dict={input_sequence: lines_ix})\n",
    "\n",
    "    # Convert translations back into strings\n",
    "    return out_voc.to_lines(trans_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample inputs: ['משתמש:צלף/!' 'סימן קריאה' 'תבנית:!!']\n",
      "Dummy translations: ['ρ$..@õ¡¡¡¡¡¡wwwמ星מ星łללοվ守ž', 'x^^^ηננ$ʿqq+רʿq+רćkṇחチוו°一', '熊$..@õ¡¡¡¡¡¡¡wwwמ星מ星łללοվ守']\n",
      "Tests passed!\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample inputs:\", all_words[:3])\n",
    "print(\"Dummy translations:\", translate(all_words[:3]))\n",
    "\n",
    "assert isinstance(greedy_translations,\n",
    "                  tf.Tensor) and greedy_translations.dtype.is_integer, \"trans must be a tensor of integers (token ids)\"\n",
    "assert translate(all_words[:3]) == translate(\n",
    "    all_words[:3]), \"make sure translation is deterministic (use greedy=True and disable any noise layers)\"\n",
    "assert type(translate(all_words[:3])) is list and (type(translate(all_words[:1])[0]) is str or type(\n",
    "    translate(all_words[:1])[0]) is unicode), \"translate(lines) must return a sequence of strings!\"\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring function\n",
    "\n",
    "LogLikelihood is a poor estimator of model performance.\n",
    "* If we predict zero probability once, it shouldn't ruin entire model.\n",
    "* It is enough to learn just one translation if there are several correct ones.\n",
    "* What matters is how many mistakes model's gonna make when it translates!\n",
    "\n",
    "Therefore, we will use minimal Levenshtein distance. It measures how many characters do we need to add/remove/replace from model translation to make it perfect. Alternatively, one could use character-level BLEU/RougeL or other similar metrics.\n",
    "\n",
    "The catch here is that Levenshtein distance is not differentiable: it isn't even continuous. We can't train our neural network to maximize it by gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import editdistance  # !pip install editdistance\n",
    "\n",
    "\n",
    "def get_distance(word, trans):\n",
    "    \"\"\"\n",
    "    A function that takes word and predicted translation\n",
    "    and evaluates (Levenshtein's) edit distance to closest correct translation\n",
    "    \"\"\"\n",
    "    references = word_to_translation[word]\n",
    "    assert len(references) != 0, \"wrong/unknown word\"\n",
    "    return min(editdistance.eval(trans, ref) for ref in references)\n",
    "\n",
    "\n",
    "def score(words, bsize=100):\n",
    "    \"\"\"a function that computes levenshtein distance for bsize random samples\"\"\"\n",
    "    assert isinstance(words, np.ndarray)\n",
    "\n",
    "    batch_words = np.random.choice(words, size=bsize, replace=False)\n",
    "    batch_trans = translate(batch_words)\n",
    "\n",
    "    distances = list(map(get_distance, batch_words, batch_trans))\n",
    "\n",
    "    return np.array(distances, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35.7, 41.6, 41.9, 26.3, 43.8]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be around 5-50 and decrease rapidly after training :)\n",
    "[score(test_words, 10).mean() for _ in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Supervised pre-training\n",
    "\n",
    "Here we define a function that trains our model through maximizing log-likelihood a.k.a. minimizing crossentropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import utility functions\n",
    "from basic_model_tf import initialize_uninitialized, infer_length, infer_mask, select_values_over_last_axis\n",
    "\n",
    "\n",
    "class supervised_training:\n",
    "\n",
    "    # variable for inputs and correct answers\n",
    "    input_sequence = tf.placeholder('int32', [None, None])\n",
    "    reference_answers = tf.placeholder('int32', [None, None])\n",
    "\n",
    "    # Compute log-probabilities of all possible tokens at each step. Use model interface.\n",
    "#     logprobs_seq = <YOUR CODE>\n",
    "    logprobs_seq = model.symbolic_score(input_sequence, reference_answers)\n",
    "\n",
    "    # compute mean crossentropy\n",
    "    crossentropy = - select_values_over_last_axis(logprobs_seq, reference_answers)\n",
    "\n",
    "    mask = infer_mask(reference_answers, out_voc.eos_ix)\n",
    "\n",
    "    loss = tf.reduce_sum(crossentropy * mask)/tf.reduce_sum(mask)\n",
    "\n",
    "    # Build weights optimizer. Use model.weights to get all trainable params.\n",
    "    train_step = tf.train.AdamOptimizer().minimize(loss, var_list=model.weights) #<YOUR CODE>\n",
    "\n",
    "\n",
    "# intialize optimizer params while keeping model intact\n",
    "initialize_uninitialized(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually run training on minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def sample_batch(words, word_to_translation, batch_size):\n",
    "    \"\"\"\n",
    "    sample random batch of words and random correct translation for each word\n",
    "    example usage:\n",
    "    batch_x,batch_y = sample_batch(train_words, word_to_translations,10)\n",
    "    \"\"\"\n",
    "    # choose words\n",
    "    batch_words = np.random.choice(words, size=batch_size)\n",
    "\n",
    "    # choose translations\n",
    "    batch_trans_candidates = list(map(word_to_translation.get, batch_words))\n",
    "    batch_trans = list(map(random.choice, batch_trans_candidates))\n",
    "\n",
    "    return inp_voc.to_matrix(batch_words), out_voc.to_matrix(batch_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:\n",
      "[[  0 117 113 137 122 130   2 127 116 118 129 122 113 129 122 128   1   1]\n",
      " [  0 113 116 118 114 117   1   1   1   1   1   1   1   1   1   1   1   1]\n",
      " [  0 113 138 125 115 128   2 117 122 116 137 118 136 130 122 116 122   1]]\n",
      "Target:\n",
      "[[ 0 40 33 50 41 51  2 45 37 36 53 46 42 33 46 41 46  1  1  1  1]\n",
      " [ 0 33 36 53 34 33  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1]\n",
      " [ 0 48 47 52 33 51 51 41 53 45  2 40 57 36 50 47 56 41 36 37  1]]\n"
     ]
    }
   ],
   "source": [
    "bx, by = sample_batch(train_words, word_to_translation, batch_size=3)\n",
    "print(\"Source:\")\n",
    "print(bx)\n",
    "print(\"Target:\")\n",
    "print(by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 900/25000 [01:02<58:27,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llh=1.796, mean score=8.366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 992/25000 [01:08<27:43, 14.44it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-be2e7110eeea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     loss, _ = s.run([supervised_training.loss,\n\u001b[0;32m---> 16\u001b[0;31m                      supervised_training.train_step], feed_dict)\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mloss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm, trange  # or use tqdm_notebook,tnrange\n",
    "\n",
    "loss_history = []\n",
    "editdist_history = []\n",
    "\n",
    "for i in trange(25000):\n",
    "    bx, by = sample_batch(train_words, word_to_translation, 32)\n",
    "\n",
    "    feed_dict = {\n",
    "        supervised_training.input_sequence: bx,\n",
    "        supervised_training.reference_answers: by\n",
    "    }\n",
    "\n",
    "    loss, _ = s.run([supervised_training.loss,\n",
    "                     supervised_training.train_step], feed_dict)\n",
    "    loss_history.append(loss)\n",
    "\n",
    "    if (i+1) % REPORT_FREQ == 0:\n",
    "        clear_output(True)\n",
    "        current_scores = score(test_words)\n",
    "        editdist_history.append(current_scores.mean())\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(131)\n",
    "        plt.title('train loss / traning time')\n",
    "        plt.plot(loss_history)\n",
    "        plt.grid()\n",
    "        plt.subplot(132)\n",
    "        plt.title('val score distribution')\n",
    "        plt.hist(current_scores, bins=20)\n",
    "        plt.subplot(133)\n",
    "        plt.title('val score / traning time')\n",
    "        plt.plot(editdist_history)\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        print(\"llh=%.3f, mean score=%.3f\" %\n",
    "              (np.mean(loss_history[-10:]), np.mean(editdist_history[-10:])))\n",
    "\n",
    "# Note: it's okay if loss oscillates up and down as long as it gets better on average over long term (e.g. 5k batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in train_words[:10]:\n",
    "    print(\"%s -> %s\" % (word, translate([word])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = []\n",
    "for start_i in trange(0, len(test_words), 32):\n",
    "    batch_words = test_words[start_i:start_i+32]\n",
    "    batch_trans = translate(batch_words)\n",
    "    distances = list(map(get_distance, batch_words, batch_trans))\n",
    "    test_scores.extend(distances)\n",
    "\n",
    "print(\"Supervised test score:\", np.mean(test_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing for reinforcement learning (2 points)\n",
    "\n",
    "First we need to define loss function as a custom tf operation.\n",
    "\n",
    "The simple way to do so is through `tensorflow.py_func` wrapper.\n",
    "```\n",
    "def my_func(x):\n",
    "  # x will be a numpy array with the contents of the placeholder below\n",
    "  return np.sinh(x)\n",
    "inp = tf.placeholder(tf.float32)\n",
    "y = tf.py_func(my_func, [inp], tf.float32)\n",
    "```\n",
    "\n",
    "\n",
    "__Your task__ is to implement `_compute_levenshtein` function that takes matrices of words and translations, along with input masks, then converts those to actual words and phonemes and computes min-levenshtein via __get_distance__ function above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_levenshtein(words_ix, trans_ix):\n",
    "    \"\"\"\n",
    "    A custom tensorflow operation that computes levenshtein loss for predicted trans.\n",
    "\n",
    "    Params:\n",
    "    - words_ix - a matrix of letter indices, shape=[batch_size,word_length]\n",
    "    - words_mask - a matrix of zeros/ones, \n",
    "       1 means \"word is still not finished\"\n",
    "       0 means \"word has already finished and this is padding\"\n",
    "\n",
    "    - trans_mask - a matrix of output letter indices, shape=[batch_size,translation_length]\n",
    "    - trans_mask - a matrix of zeros/ones, similar to words_mask but for trans_ix\n",
    "\n",
    "\n",
    "    Please implement the function and make sure it passes tests from the next cell.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # convert words to strings\n",
    "    words = <YOUR CODE: restore words (a list of strings) from words_ix. Use vocab>\n",
    "\n",
    "    assert type(words) is list and type(\n",
    "        words[0]) is str and len(words) == len(words_ix)\n",
    "\n",
    "    # convert translations to lists\n",
    "    translations = <YOUR CODE: restore trans (a list of lists of phonemes) from trans_ix\n",
    "\n",
    "    assert type(translations) is list and type(\n",
    "        translations[0]) is str and len(translations) == len(trans_ix)\n",
    "\n",
    "    # computes levenstein distances. can be arbitrary python code.\n",
    "    distances = <YOUR CODE: apply get_distance to each pair of [words, translations]>\n",
    "\n",
    "    assert type(distances) in (list, tuple, np.ndarray) and len(\n",
    "        distances) == len(words_ix)\n",
    "\n",
    "    distances = np.array(list(distances), dtype='float32')\n",
    "    return distances\n",
    "\n",
    "\n",
    "def compute_levenshtein(words_ix, trans_ix):\n",
    "    out = tf.py_func(_compute_levenshtein, [words_ix, trans_ix, ], tf.float32)\n",
    "    out.set_shape([None])\n",
    "\n",
    "    return tf.stop_gradient(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple test suite to make sure your implementation is correct. Hint: if you run into any bugs, feel free to use print from inside _compute_levenshtein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test suite\n",
    "# sample random batch of (words, correct trans, wrong trans)\n",
    "batch_words = np.random.choice(train_words, size=100)\n",
    "batch_trans = list(map(random.choice, map(\n",
    "    word_to_translation.get, batch_words)))\n",
    "batch_trans_wrong = np.random.choice(all_translations, size=100)\n",
    "\n",
    "batch_words_ix = tf.constant(inp_voc.to_matrix(batch_words))\n",
    "batch_trans_ix = tf.constant(out_voc.to_matrix(batch_trans))\n",
    "batch_trans_wrong_ix = tf.constant(out_voc.to_matrix(batch_trans_wrong))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert compute_levenshtein is zero for ideal translations\n",
    "correct_answers_score = compute_levenshtein(\n",
    "    batch_words_ix, batch_trans_ix).eval()\n",
    "\n",
    "assert np.all(correct_answers_score ==\n",
    "              0), \"a perfect translation got nonzero levenshtein score!\"\n",
    "\n",
    "print(\"Everything seems alright!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert compute_levenshtein matches actual scoring function\n",
    "wrong_answers_score = compute_levenshtein(\n",
    "    batch_words_ix, batch_trans_wrong_ix).eval()\n",
    "\n",
    "true_wrong_answers_score = np.array(\n",
    "    list(map(get_distance, batch_words, batch_trans_wrong)))\n",
    "\n",
    "assert np.all(wrong_answers_score ==\n",
    "              true_wrong_answers_score), \"for some word symbolic levenshtein is different from actual levenshtein distance\"\n",
    "\n",
    "print(\"Everything seems alright!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you got it working...\n",
    "\n",
    "\n",
    "* You may now want to __remove/comment asserts__ from function code for a slight speed-up.\n",
    "\n",
    "* There's a more detailed tutorial on custom tensorflow ops: [`py_func`](https://www.tensorflow.org/api_docs/python/tf/py_func), [`low-level`](https://www.tensorflow.org/api_docs/python/tf/py_func)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Self-critical policy gradient (2 points)\n",
    "\n",
    "In this section you'll implement algorithm called self-critical sequence training (here's an [article](https://arxiv.org/abs/1612.00563)).\n",
    "\n",
    "The algorithm is a vanilla policy gradient with a special baseline. \n",
    "\n",
    "$$ \\nabla J = E_{x \\sim p(s)} E_{y \\sim \\pi(y|x)} \\nabla log \\pi(y|x) \\cdot (R(x,y) - b(x)) $$\n",
    "\n",
    "Here reward R(x,y) is a __negative levenshtein distance__ (since we minimize it). The baseline __b(x)__ represents how well model fares on word __x__.\n",
    "\n",
    "In practice, this means that we compute baseline as a score of greedy translation, $b(x) = R(x,y_{greedy}(x)) $.\n",
    "\n",
    "![img](https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/scheme.png)\n",
    "Luckily, we already obtained the required outputs: `model.greedy_translations, model.greedy_mask` and we only need to compute levenshtein using `compute_levenshtein` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainer:\n",
    "\n",
    "    input_sequence = tf.placeholder('int32', [None, None])\n",
    "\n",
    "    # use model to __sample__ symbolic translations given input_sequence\n",
    "    sample_translations, sample_logp = <YOUR CODE>\n",
    "    # use model to __greedy__ symbolic translations given input_sequence\n",
    "    greedy_translations, greedy_logp = <YOUR CODE>\n",
    "\n",
    "    rewards = - compute_levenshtein(input_sequence, sample_translations)\n",
    "\n",
    "    # compute __negative__ levenshtein for greedy mode\n",
    "    baseline = <YOUR CODE>\n",
    "\n",
    "    # compute advantage using rewards and baseline\n",
    "    advantage = <YOUR CODE: compute advantage>\n",
    "    assert advantage.shape.ndims == 1, \"advantage must be of shape [batch_size]\"\n",
    "\n",
    "    # compute log_pi(a_t|s_t), shape = [batch, seq_length]\n",
    "    logprobs_phoneme = <YOUR CODE>\n",
    "    # ^-- hint: look at how crossentropy is implemented in supervised learning loss above\n",
    "    # mind the sign - this one should not be multiplied by -1 :)\n",
    "\n",
    "\n",
    "    # Compute policy gradient\n",
    "    # or rather surrogate function who's gradient is policy gradient\n",
    "    J = logprobs_phoneme*advantage[:, None]\n",
    "\n",
    "    mask = infer_mask(sample_translations, out_voc.eos_ix)\n",
    "    loss = - tf.reduce_sum(J*mask) / tf.reduce_sum(mask)\n",
    "\n",
    "    # regularize with negative entropy. Don't forget the sign!\n",
    "    # note: for entropy you need probabilities for all tokens (sample_logp), not just phoneme_logprobs\n",
    "    entropy = <compute entropy matrix of shape[batch, seq_length], H = -sum(p*log_p), don't forget the sign!>\n",
    "    # hint: you can get sample probabilities from sample_logp using math :)\n",
    "\n",
    "\n",
    "    assert entropy.shape.ndims == 2, \"please make sure elementwise entropy is of shape [batch,time]\"\n",
    "\n",
    "    loss -= 0.01*tf.reduce_sum(entropy*mask) / tf.reduce_sum(mask)\n",
    "\n",
    "    # compute weight updates, clip by norm\n",
    "    grads = tf.gradients(loss, model.weights)\n",
    "    grads = tf.clip_by_global_norm(grads, 50)[0]\n",
    "\n",
    "    train_step = tf.train.AdamOptimizer(\n",
    "        learning_rate=1e-5).apply_gradients(zip(grads, model.weights,))\n",
    "\n",
    "\n",
    "initialize_uninitialized()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy gradient training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in trange(100000):\n",
    "    bx = sample_batch(train_words, word_to_translation, 32)[0]\n",
    "    pseudo_loss, _ = s.run([trainer.loss, trainer.train_step], {\n",
    "                           trainer.input_sequence: bx})\n",
    "\n",
    "    loss_history.append(\n",
    "        pseudo_loss\n",
    "    )\n",
    "\n",
    "    if (i+1) % REPORT_FREQ == 0:\n",
    "        clear_output(True)\n",
    "        current_scores = score(test_words)\n",
    "        editdist_history.append(current_scores.mean())\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.subplot(121)\n",
    "        plt.title('val score distribution')\n",
    "        plt.hist(current_scores, bins=20)\n",
    "        plt.subplot(122)\n",
    "        plt.title('val score / traning time')\n",
    "        plt.plot(editdist_history)\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        print(\"J=%.3f, mean score=%.3f\" %\n",
    "              (np.mean(loss_history[-10:]), np.mean(editdist_history[-10:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in train_words[:10]:\n",
    "    print(\"%s -> %s\" % (word, translate([word])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = []\n",
    "for start_i in trange(0, len(test_words), 32):\n",
    "    batch_words = test_words[start_i:start_i+32]\n",
    "    batch_trans = translate(batch_words)\n",
    "    distances = list(map(get_distance, batch_words, batch_trans))\n",
    "    test_scores.extend(distances)\n",
    "print(\"Supervised test score:\", np.mean(test_scores))\n",
    "\n",
    "# ^^ If you get Out Of Memory, please replace this with batched computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Make it actually work (5++ pts)\n",
    "<img src=https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/do_something_scst.png width=400>\n",
    "\n",
    "In this section we want you to finally __restart with EASY_MODE=False__ and experiment to find a good model/curriculum for that task.\n",
    "\n",
    "We recommend you to start with the following architecture\n",
    "\n",
    "```\n",
    "encoder---decoder\n",
    "\n",
    "           P(y|h)\n",
    "             ^\n",
    " LSTM  ->   LSTM\n",
    "  ^          ^\n",
    " biLSTM  ->   LSTM\n",
    "  ^          ^\n",
    "input       y_prev\n",
    "```\n",
    "\n",
    "__Note:__ you can fit all 4 state tensors of both LSTMs into a in a single state - just assume that it contains, for example, [h0, c0, h1, c1] - pack it in encode and update in decode.\n",
    "\n",
    "\n",
    "Here are some cool ideas on what you can do then.\n",
    "\n",
    "__General tips & tricks:__\n",
    "* In some tensorflow versions and for some layers, it is required that each rnn/gru/lstm cell gets it's own `tf.variable_scope(unique_name, reuse=False)`.\n",
    "  * Otherwise it will complain about wrong tensor sizes because it tries to reuse weights from one rnn to the other.\n",
    "* You will likely need to adjust pre-training time for such a network.\n",
    "* Supervised pre-training may benefit from clipping gradients somehow.\n",
    "* SCST may indulge a higher learning rate in some cases and changing entropy regularizer over time.\n",
    "* It's often useful to save pre-trained model parameters to not re-train it every time you want new policy gradient parameters. \n",
    "* When leaving training for nighttime, try setting REPORT_FREQ to a larger value (e.g. 500) not to waste time on it.\n",
    "\n",
    "__Formal criteria:__\n",
    "To get 5 points we want you to build an architecture that:\n",
    "* _doesn't consist of single GRU_\n",
    "* _works better_ than single GRU baseline. \n",
    "* We also want you to provide either learning curve or trained model, preferably both\n",
    "* ... and write a brief report or experiment log describing what you did and how it fared.\n",
    "\n",
    "### Attention\n",
    "There's more than one way to connect decoder to encoder\n",
    "  * __Vanilla:__ layer_i of encoder last state goes to layer_i of decoder initial state\n",
    "  * __Every tick:__ feed encoder last state _on every iteration_ of decoder.\n",
    "  * __Attention:__ allow decoder to \"peek\" at one (or several) positions of encoded sequence on every tick.\n",
    "  \n",
    "The most effective (and cool) of those is, of course, attention.\n",
    "You can read more about attention [in this nice blog post](https://distill.pub/2016/augmented-rnns/). The easiest way to begin is to use \"soft\" attention with \"additive\" or \"dot-product\" intermediate layers.\n",
    "\n",
    "__Tips__\n",
    "* Model usually generalizes better if you no longer allow decoder to see final encoder state\n",
    "* Once your model made it through several epochs, it is a good idea to visualize attention maps to understand what your model has actually learned\n",
    "\n",
    "* There's more stuff [here](https://github.com/yandexdataschool/Practical_RL/blob/master/week8_scst/bonus.ipynb)\n",
    "* If you opted for hard attention, we recommend [gumbel-softmax](https://blog.evjang.com/2016/11/tutorial-categorical-variational.html) instead of sampling. Also please make sure soft attention works fine before you switch to hard.\n",
    "\n",
    "### UREX\n",
    "* This is a way to improve exploration in policy-based settings. The main idea is that you find and upweight under-appreciated actions.\n",
    "* Here's [video](https://www.youtube.com/watch?v=fZNyHoXgV7M&feature=youtu.be&t=3444)\n",
    " and an [article](https://arxiv.org/abs/1611.09321).\n",
    "* You may want to reduce batch size 'cuz UREX requires you to sample multiple times per source sentence.\n",
    "* Once you got it working, try using experience replay with importance sampling instead of (in addition to) basic UREX.\n",
    "\n",
    "### Some additional ideas:\n",
    "* (advanced deep learning) It may be a good idea to first train on small phrases and then adapt to larger ones (a.k.a. training curriculum).\n",
    "* (advanced nlp) You may want to switch from raw utf8 to something like unicode or even syllables to make task easier.\n",
    "* (advanced nlp) Since hebrew words are written __with vowels omitted__, you may want to use a small Hebrew vowel markup dataset at `he-pron-wiktionary.txt`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus hints: [here](https://github.com/yandexdataschool/Practical_RL/blob/master/week8_scst/bonus.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not EASY_MODE, \"make sure you set EASY_MODE = False at the top of the notebook.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`[your report/log here or anywhere you please]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Contributions:__ This notebook is brought to you by\n",
    "* Yandex [MT team](https://tech.yandex.com/translate/)\n",
    "* Denis Mazur ([DeniskaMazur](https://github.com/DeniskaMazur)), Oleg Vasilev ([Omrigan](https://github.com/Omrigan/)), Dmitry Emelyanenko ([TixFeniks](https://github.com/tixfeniks)) and Fedor Ratnikov ([justheuristic](https://github.com/justheuristic/))\n",
    "* Dataset is parsed from [Wiktionary](https://en.wiktionary.org), which is under CC-BY-SA and GFDL licenses.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
